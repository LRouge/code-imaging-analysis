{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0efc19cd",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "#from skimage.io import imread\n",
    "#import pyclesperanto_prototype as cle  # version 0.19.4\n",
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from skimage.io import imread "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a3af478-892b-46d7-997b-77c3a624efc5",
   "metadata": {},
   "source": [
    "**Preliminary question to find the files and the status of the analysis** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ba81074-9478-4a48-b3f5-b7fb7b4a1610",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "first_time = input(\"Is this the first strain?(yes/no)\")\n",
    "first_field = input(\"Is this the first field of view for this strain?(yes/no)\")\n",
    "folder = input(\"Paste the URL of where you  want to save/upload data\")\n",
    "folder_path = Path(folder)\n",
    "filename = \"intensity.csv\"\n",
    "full_path = folder_path.joinpath(filename)\n",
    "strain = input(\"Enter the strain name: \")\n",
    "\n",
    "intensity_dict = []\n",
    "if first_time == \"no\":\n",
    "    intensity_df = pd.read_csv(full_path)\n",
    "    # convert the dataframe to a dictionary\n",
    "    intensity_dict = intensity_df.to_dict('records')\n",
    "\n",
    "n_worm = 0    \n",
    "if first_field == \"no\":\n",
    "    for data_dict in intensity_dict:\n",
    "        if str(data_dict['strain']) == str(strain) and data_dict['worm'] > n_worm:\n",
    "            n_worm = data_dict['worm']\n",
    "\n",
    "print(\"number of worms already analysed\")\n",
    "n_worm            "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0849cb95-ae0b-4dc3-9b7e-c247223dc6a9",
   "metadata": {},
   "source": [
    "**Getting into the folder where imagese are**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e7ab040-397d-4641-b93a-e11487b89529",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "directory  = r\"S:\\microscopy\\HSP\\24.05.16 srx-9\\3472\\analysis\"\n",
    "directory_path = Path(directory)\n",
    "strain_file= input(\"Enter the field of view name: \")\n",
    "strain_file_format = strain_file+ '.tif'\n",
    "# Import functions from the custom module binding_box_finder\n",
    "from binding_box_finder_v14 import blob_maker_DIC, binding_box_find_and_display\n",
    "images  = imread(os.path.join(directory_path, strain_file_format))\n",
    "images = images[:,:,:]\n",
    "w, h = images[0].shape\n",
    "\n",
    "w_2_3 = 2 * int(w/3)\n",
    "w_3 = int(w/3)\n",
    "h_2_3 = 2 * int(h/3)\n",
    "h_3 = int(h/3)\n",
    "\n",
    "coord_list = [(0, 0, w_3, h_3), (0, h_3, w_3, h_3), (0, h_2_3, w_3, h_3), \n",
    "             (w_3, 0, w_3, h_3), (w_3, h_3, w_3, h_3), (w_3, h_2_3, w_3, h_3),\n",
    "             (w_2_3, 0, w_3, h_3), (w_2_3, h_3, w_3, h_3), (w_2_3, h_2_3, w_3, h_3)]\n",
    "\n",
    "coord_list = [\n",
    "             (w_3, h_3, w_3, h_3), \n",
    "             (w_2_3, 0, w_3, h_3), (w_2_3, h_3, w_3, h_3), (w_2_3, h_2_3, w_3, h_3)]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a0e9274-b05e-4089-8be6-d4bccf6e935c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Import the draw_boxes_from_coordinates function from the custom module binding_box_finder\n",
    "from binding_box_finder_v14 import draw_boxes_from_coordinates as dbfc\n",
    "\n",
    "# Specify the filename for the image with drawn bounding boxes\n",
    "filename_boxes = os.path.join(directory_path, 'boxes_' + strain_file + '.jpeg')\n",
    "\n",
    "\n",
    "# Use the draw_boxes_from_coordinates function to draw bounding boxes on the first image in images_gcamp\n",
    "# The function likely takes coord_list, the image, and the filename as parameters\n",
    "_ = dbfc(coord_list, np.max(images, axis=0), filename_boxes, n_worm+1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e784404f-37f9-43da-8d16-7bf9c884d258",
   "metadata": {},
   "source": [
    "**Single worm analysis, getting mean intensity**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d129d272-208c-4fdd-a480-06d01afd9c2b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from skimage import filters\n",
    "\n",
    "# Iterate through each day's image in the dataset\n",
    "for day, img in enumerate(images):\n",
    "    \n",
    "    if first_field == \"no\":\n",
    "        n_worm = data_dict['worm']\n",
    "    else: \n",
    "        n_worm = 0\n",
    "    # Iterate through the list of worm coordinates\n",
    "    for xy in coord_list:\n",
    "        n_worm += 1 \n",
    "        x,y, w, h = xy\n",
    "        # Extract the worm region from the image\n",
    "        worm  = img[y:(y+h), x:(x+w)]\n",
    "        # Apply Otsu's thresholding for binarization\n",
    "        worm_trash = filters.threshold_otsu(worm)\n",
    "        # Feature extraction: Identify pixels above the threshold\n",
    "        worm_over_trash = worm > worm_trash\n",
    "        # Compute mean intensity of the worm region above the threshold\n",
    "        worm_itensity = np.nanmean(worm[worm_over_trash])\n",
    "        \n",
    "        # Create a dictionary to store extracted data for the worm\n",
    "        worm_data = {\"day\": int(day+1), \"strain\":str(strain), \"worm\": int(n_worm), \"mean_intensity\": float(worm_itensity)}\n",
    "        \n",
    "        # Append the worm data dictionary to the list\n",
    "        intensity_dict.append(worm_data)\n",
    "      \n",
    "        \n",
    "# create the dataframe from the list of data\n",
    "intensity_df = pd.DataFrame(intensity_dict)\n",
    "# save the dataframe as csv file without index\n",
    "intensity_df.to_csv(full_path, index=False) #False exclude index column\n",
    "\n",
    "intensity_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea9b0225-9cad-4c0c-8054-612254a1f788",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "folder_path2 = Path(r'S:\\microscopy\\HSP\\24.05.28 srx-9\\3472\\analysis')\n",
    "plot_data = pd.read_csv(folder_path2.joinpath(\"intensity_norm_rep1.csv\"))\n",
    "\n",
    "\n",
    "normalized_df = plot_data\n",
    "plot_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23af746a-0087-403b-b252-a14016e4fde9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# a list of tuples where each tuple is (strain, worm)\n",
    "worms_to_remove = [(3470, 3), (3470, 6), (3470, 12), (3470, 14), (3470, 16), (3470, 20), (3470, 23), (3470, 25), (3470, 31)]\n",
    "\n",
    "# Filter the data\n",
    "for strain, w in worms_to_remove:\n",
    "    plot_data = plot_data[~((plot_data['strain'] == strain) & (plot_data['worm'] == w))]\n",
    "\n",
    "normalized_df = plot_data\n",
    "plot_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6258ee7-c07f-453d-8e72-e0d8eabd0e72",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Function to normalize intensity measurements relative to day 1\n",
    "def normalize_group(group):\n",
    "    # Check if there is a day 1 measurement\n",
    "    if 1 in group['day'].values:\n",
    "        day_1_mean_intensity = group.loc[group['day'] == 1, 'mean_intensity'].values[0]\n",
    "        # Compute normalized intensity as a fraction of day 1's intensity\n",
    "        group['normalized_intensity'] = (group['mean_intensity'] - day_1_mean_intensity) / day_1_mean_intensity\n",
    "    else:\n",
    "        group['normalized_intensity'] = None  # Assign None if day 1 data is missing\n",
    "    return group\n",
    "\n",
    "# Apply normalization for each worm within each strain and replicate group\n",
    "normalized_df = plot_data.groupby(['strain', 'worm', 'replicate']).apply(normalize_group)\n",
    "\n",
    "\n",
    "\n",
    "# Reset index to keep the dataframe clean\n",
    "normalized_df = normalized_df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f864f3b7-2887-415e-a716-091619e04390",
   "metadata": {},
   "outputs": [],
   "source": [
    "normalized_df.to_csv(folder_path2.joinpath('intensity_norm.csv'), index=False) #False exclude index column\n",
    "normalized_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a2fa2a0-c15d-42bd-9da4-3454cacdc239",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group by strain\n",
    "grouped_norm = normalized_df.groupby(['strain', 'day'])\n",
    "# Calculate the mean normalized intensity for each group\n",
    "mean_by_group = grouped_norm['normalized_intensity'].mean()\n",
    "# Calculate the standard deviation for each group\n",
    "std_by_group = grouped_norm['normalized_intensity'].std()\n",
    "# Count the number of worms for each group\n",
    "count_by_group = grouped_norm['normalized_intensity'].count()\n",
    "# Calculate the standard error for each group\n",
    "standard_error_by_group = std_by_group / np.sqrt(count_by_group)\n",
    "\n",
    "# Create a new DataFrame containing the strain, day, mean normalized intensity, and standard error\n",
    "avg_norm_df = pd.DataFrame({\n",
    "    'strain': mean_by_group.index.get_level_values('strain'),\n",
    "    'day': mean_by_group.index.get_level_values('day'),\n",
    "    'mean_normalized_intensity': mean_by_group.values,\n",
    "    'standard_error': standard_error_by_group.values\n",
    "})\n",
    "\n",
    "avg_norm_df.to_csv(folder_path2.joinpath('intensity_avg_norm_error.csv'), index=False) \n",
    "avg_norm_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9addb47-2507-4ae6-aca9-c06794458f1d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
